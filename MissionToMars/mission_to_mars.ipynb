{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c24d95",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web Scraping\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection Function\n",
    "def connect(url:str) -> str:\n",
    "    # Setup splinter\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "    #Page URL\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #Soup Creation\n",
    "    html = browser.html\n",
    "    cout = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    #Exit Browser\n",
    "    browser.quit()\n",
    "\n",
    "    return cout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807ecd9",
   "metadata": {},
   "source": [
    "### Mars Article Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://redplanetscience.com/'\n",
    "soup = connect(url)\n",
    "\n",
    "news_title = soup.find_all('div', class_ = 'content_title')\n",
    "news_p = soup.find_all('div', class_ = 'article_teaser_body')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first element in string output and its text \n",
    "first_title = news_title[0].text\n",
    "first_p = news_p[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c83f3",
   "metadata": {},
   "source": [
    "### Mars Image Web Scrape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://spaceimages-mars.com/'\n",
    "soup = connect(url)\n",
    "\n",
    "featured_url = soup.find_all('img', class_ = 'headerimage fade-in')[0]['src']\n",
    "image_url = url + featured_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86022f8",
   "metadata": {},
   "source": [
    "### Mars Facts Web Scrape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Page URL\n",
    "url = 'https://galaxyfacts-mars.com/'\n",
    "\n",
    "mars_table = pd.read_html(url)[1]\n",
    "\n",
    "print(mars_table.to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69eeeb",
   "metadata": {},
   "source": [
    "### Mars Hemisphere Images Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://marshemispheres.com/'\n",
    "\n",
    "soup = connect(url)\n",
    "\n",
    "\n",
    "#scrape all relative paths\n",
    "rel_path_list = soup.find_all('a', class_ = 'itemLink product-item')\n",
    "html_path = [path['href'] for path in rel_path_list]\n",
    "\n",
    "#remove duplicates\n",
    "html_path = list(set(html_path))\n",
    "\n",
    "#remove blank paths\n",
    "temp_html = []\n",
    "for path in html_path:\n",
    "    if path[0] != '#':\n",
    "        temp_html.append(path)\n",
    "html_path = temp_html\n",
    "\n",
    "#Append url to relative path\n",
    "html_path = [url + path for path in html_path]\n",
    "\n",
    "#Visit each url and pull the image url and title\n",
    "image_path = []\n",
    "for path in html_path:\n",
    "    image_dict = {}\n",
    "    #try:\n",
    "    #visit each path and load html\n",
    "    soup = connect(path)\n",
    "\n",
    "    #find relevant data from html soup\n",
    "    title_text = soup.find_all('h2', class_='title')[0].text\n",
    "    img_url = url + (soup.find_all('a')[3]['href'])\n",
    "\n",
    "    #add data to list dict obj \n",
    "    image_dict['title'] = title_text[0:len(title_text)-9]\n",
    "    image_dict['img_url'] = img_url \n",
    "    image_path.append(image_dict)       \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
